{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1c8069f-2f41-4b15-bbd0-a84ff8cc68fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pennylane\n",
      "  Downloading PennyLane-0.36.0-py3-none-any.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: numpy<2.0 in c:\\users\\intern13\\appdata\\roaming\\python\\python311\\site-packages (from pennylane) (1.26.4)\n",
      "Requirement already satisfied: scipy in c:\\users\\intern13\\appdata\\roaming\\python\\python311\\site-packages (from pennylane) (1.13.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\intern13\\anaconda3\\lib\\site-packages (from pennylane) (3.1)\n",
      "Requirement already satisfied: rustworkx in c:\\users\\intern13\\appdata\\roaming\\python\\python311\\site-packages (from pennylane) (0.14.2)\n",
      "Collecting autograd (from pennylane)\n",
      "  Downloading autograd-1.6.2-py3-none-any.whl.metadata (706 bytes)\n",
      "Requirement already satisfied: toml in c:\\users\\intern13\\anaconda3\\lib\\site-packages (from pennylane) (0.10.2)\n",
      "Requirement already satisfied: appdirs in c:\\users\\intern13\\anaconda3\\lib\\site-packages (from pennylane) (1.4.4)\n",
      "Collecting semantic-version>=2.7 (from pennylane)\n",
      "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
      "Collecting autoray>=0.6.1 (from pennylane)\n",
      "  Downloading autoray-0.6.12-py3-none-any.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: cachetools in c:\\users\\intern13\\anaconda3\\lib\\site-packages (from pennylane) (4.2.2)\n",
      "Collecting pennylane-lightning>=0.36 (from pennylane)\n",
      "  Downloading PennyLane_Lightning-0.36.0-cp311-cp311-win_amd64.whl.metadata (21 kB)\n",
      "Requirement already satisfied: requests in c:\\users\\intern13\\anaconda3\\lib\\site-packages (from pennylane) (2.31.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\intern13\\anaconda3\\lib\\site-packages (from pennylane) (4.9.0)\n",
      "Requirement already satisfied: future>=0.15.2 in c:\\users\\intern13\\anaconda3\\lib\\site-packages (from autograd->pennylane) (0.18.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\intern13\\anaconda3\\lib\\site-packages (from requests->pennylane) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\intern13\\anaconda3\\lib\\site-packages (from requests->pennylane) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\intern13\\anaconda3\\lib\\site-packages (from requests->pennylane) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\intern13\\anaconda3\\lib\\site-packages (from requests->pennylane) (2024.2.2)\n",
      "Downloading PennyLane-0.36.0-py3-none-any.whl (1.7 MB)\n",
      "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "   ---------------------------------------  1.7/1.7 MB 104.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.7/1.7 MB 104.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.7/1.7 MB 11.9 MB/s eta 0:00:00\n",
      "Downloading autoray-0.6.12-py3-none-any.whl (50 kB)\n",
      "   ---------------------------------------- 0.0/51.0 kB ? eta -:--:--\n",
      "   -------------------------------- ------- 41.0/51.0 kB ? eta -:--:--\n",
      "   -------------------------------- ------- 41.0/51.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 51.0/51.0 kB 515.3 kB/s eta 0:00:00\n",
      "Downloading PennyLane_Lightning-0.36.0-cp311-cp311-win_amd64.whl (5.6 MB)\n",
      "   ---------------------------------------- 0.0/5.6 MB ? eta -:--:--\n",
      "   ----------------------- ---------------- 3.2/5.6 MB 68.6 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 3.9/5.6 MB 41.1 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 4.6/5.6 MB 32.2 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 5.2/5.6 MB 27.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  5.6/5.6 MB 25.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  5.6/5.6 MB 25.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  5.6/5.6 MB 25.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 5.6/5.6 MB 17.0 MB/s eta 0:00:00\n",
      "Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
      "Downloading autograd-1.6.2-py3-none-any.whl (49 kB)\n",
      "   ---------------------------------------- 0.0/49.3 kB ? eta -:--:--\n",
      "   --------------------------------- ------ 41.0/49.3 kB ? eta -:--:--\n",
      "   --------------------------------- ------ 41.0/49.3 kB ? eta -:--:--\n",
      "   --------------------------------- ------ 41.0/49.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 49.3/49.3 kB 276.7 kB/s eta 0:00:00\n",
      "Installing collected packages: semantic-version, autoray, autograd, pennylane-lightning, pennylane\n",
      "Successfully installed autograd-1.6.2 autoray-0.6.12 pennylane-0.36.0 pennylane-lightning-0.36.0 semantic-version-2.10.0\n"
     ]
    }
   ],
   "source": [
    "!pip install pennylane\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pennylane as qml\n",
    "import tkinter as tk\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from joblib import dump\n",
    "from PIL import Image, ImageTk\n",
    "from pennylane import numpy as np\n",
    "from pennylane.optimize import NesterovMomentumOptimizer\n",
    "from tkinter import filedialog, messagebox, simpledialog "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e8d389-5dee-45d2-a4bb-93ad9bc9d892",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Initialize global variables\n",
    "scaler = StandardScaler()\n",
    "num_qubits = 4\n",
    "num_layers = 2\n",
    "learning_rate = 0.1\n",
    "epochs = 50\n",
    "dev = qml.device(\"default.qubit\", wires=num_qubits)\n",
    "\n",
    "# Global variable to hold the PhotoImage object\n",
    "background_photo = None\n",
    "\n",
    "# Define quantum circuit and cost function\n",
    "def circuit(params, x):\n",
    "    qml.templates.AngleEmbedding(x, wires=range(num_qubits))\n",
    "    qml.templates.StronglyEntanglingLayers(params, wires=range(num_qubits))\n",
    "    return qml.expval(qml.PauliZ(0))\n",
    "\n",
    "@qml.qnode(dev)\n",
    "def qnode(params, x):\n",
    "    circuit(params, x)\n",
    "    return qml.expval(qml.PauliZ(0))\n",
    "\n",
    "def cost(params, X, y):\n",
    "    predictions = np.array([qnode(params, x) for x in X])\n",
    "    return np.mean((predictions - y) ** 2)\n",
    "\n",
    "# Data preprocessing function\n",
    "def preprocess_data(file_path, target_column):\n",
    "    global scaler\n",
    "\n",
    "    if file_path.endswith('.csv'):\n",
    "        df = pd.read_csv(file_path, chunksize=1000)  \n",
    "    elif file_path.endswith(('.xls', '.xlsx')):\n",
    "        df = pd.read_excel(file_path)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported file format. Please select a CSV or Excel file.\")\n",
    "\n",
    "    features_list = []\n",
    "    targets_list = []\n",
    "\n",
    "    for chunk in df:\n",
    "        numeric_columns = chunk.select_dtypes(include=[np.number]).columns.tolist()\n",
    "        selected_features = numeric_columns[:min(len(numeric_columns), num_qubits)] \n",
    "        selected_features.remove(target_column) \n",
    "\n",
    "        chunk_features = chunk[selected_features].values.tolist()\n",
    "        chunk_targets = chunk[target_column].values.tolist()\n",
    "        features_list.extend(chunk_features)\n",
    "        targets_list.extend(chunk_targets)\n",
    "    features = np.array(features_list)\n",
    "    targets = np.array(targets_list)\n",
    "    features = pd.DataFrame(features, columns=selected_features)\n",
    "    features.fillna(features.mean(), inplace=True)\n",
    "    scaled_features = scaler.fit_transform(features)\n",
    "    selector = SelectKBest(score_func=f_classif, k=min(num_qubits, scaled_features.shape[1]))\n",
    "    selected_features = selector.fit_transform(scaled_features, targets)\n",
    "\n",
    "    return selected_features, targets, scaler\n",
    "\n",
    "# Training and prediction function\n",
    "def train_and_predict(features, target):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "    params = np.random.randn(num_layers, num_qubits, 3)\n",
    "    opt = NesterovMomentumOptimizer(learning_rate)\n",
    "    for epoch in range(epochs):\n",
    "        params = opt.step(lambda v: cost(v, X_train, y_train), params)\n",
    "\n",
    "    y_pred = np.array([np.sign(qnode(params, x)) for x in X_test])\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    report = classification_report(y_test, y_pred)\n",
    "    return accuracy, report, params\n",
    "\n",
    "# File selection and processing function\n",
    "def on_file_select():\n",
    "    global background_photo\n",
    "\n",
    "    file_path = filedialog.askopenfilename(filetypes=[(\"CSV files\", \"*.csv\"), (\"Excel files\", \"*.xls *.xlsx\")])\n",
    "    if not file_path:\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        if file_path.endswith('.csv'):\n",
    "            df = pd.read_csv(file_path)\n",
    "        elif file_path.endswith(('.xls', '.xlsx')):\n",
    "            df = pd.read_excel(file_path)\n",
    "            \n",
    "        target_column = simpledialog.askstring(\"Input\", f\"Available columns:\\n{', '.join(df.columns)}\\n\\nPlease enter the target column:\")\n",
    "\n",
    "        if target_column not in df.columns:\n",
    "            raise ValueError(\"Selected target column not found in the file.\")\n",
    "\n",
    "        features, target, scaler = preprocess_data(file_path, target_column)\n",
    "        accuracy, report, params = train_and_predict(features, target)\n",
    "\n",
    "        update_results_display(accuracy, report)\n",
    "\n",
    "        dump(params, 'quantum_model_params.pkl')\n",
    "        messagebox.showinfo(\"Success\", \"Model trained and predictions displayed!\")\n",
    "    except Exception as e:\n",
    "        messagebox.showerror(\"Error\", f\"Error occurred: {str(e)}\")\n",
    "\n",
    "# Function to update results and show background when necessary\n",
    "def update_results_display(accuracy, report):\n",
    "    results_text.config(state=tk.NORMAL)\n",
    "    results_text.delete(1.0, tk.END)\n",
    "    results_text.insert(tk.END, f\"Accuracy: {accuracy}\\n\\nClassification Report:\\n{report}\")\n",
    "    \n",
    "    # Check if there is content to display\n",
    "    if accuracy == 0.0 and report.strip() == \"\":\n",
    "        results_frame.configure(bg=\"rgba(255, 255, 255, 0.5)\")  # Transparent white background\n",
    "    else:\n",
    "        results_frame.configure(bg=\"white\")  # Solid white background\n",
    "    \n",
    "    results_text.config(state=tk.DISABLED)\n",
    "\n",
    "# GUI setup\n",
    "root = tk.Tk()\n",
    "root.title(\"Quantum Machine Learning Model Trainer\")\n",
    "root.geometry(\"800x600\")\n",
    "\n",
    "# Load and set the background image\n",
    "try:\n",
    "    background_image = Image.open(r\"C:\\Users\\Intern13\\Desktop\\project\\testing\\test.jpg\")  # Replace with the path to your background image\n",
    "    background_photo = ImageTk.PhotoImage(background_image)\n",
    "    background_label = tk.Label(root, image=background_photo)\n",
    "    background_label.place(x=0, y=0, relwidth=1, relheight=1)\n",
    "except Exception as e:\n",
    "    print(f\"Error loading background image: {e}\")\n",
    "\n",
    "# Create a frame for the header and button\n",
    "header_frame = tk.Frame(root, bg=\"#333\")\n",
    "header_frame.pack(fill=tk.X, pady=20)\n",
    "\n",
    "header_label = tk.Label(header_frame, text=\"Quantum Machine Learning Model Trainer\", fg=\"white\", bg=\"#333\", font=(\"Helvetica\", 16, \"bold\"))\n",
    "header_label.pack(pady=10)\n",
    "\n",
    "select_file_button = tk.Button(header_frame, text=\"Select CSV or Excel File\", command=on_file_select, bg=\"#4CAF50\", fg=\"white\", font=(\"Helvetica\", 12, \"bold\"))\n",
    "select_file_button.pack(pady=10)\n",
    "\n",
    "# Create a frame for the results\n",
    "results_frame = tk.LabelFrame(root, text=\"Results\", font=(\"Helvetica\", 14, \"bold\"), bg=\"white\", relief=tk.SOLID, borderwidth=1)  # Solid white background\n",
    "results_frame.pack(fill=tk.BOTH, expand=True, padx=20, pady=10)\n",
    "\n",
    "# Use a text widget for results\n",
    "results_text = tk.Text(results_frame, wrap=tk.WORD, state=tk.DISABLED, font=(\"Helvetica\", 12))\n",
    "results_text.pack(fill=tk.BOTH, expand=True)\n",
    "\n",
    "root.mainloop()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
